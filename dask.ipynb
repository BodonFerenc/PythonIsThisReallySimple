{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NROFCORES=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTable(rowCount):\n",
    "    gc.collect()\n",
    "    return dd.from_pandas(pd.DataFrame({'bucket': [''.join(random.choices(string.ascii_lowercase, k=2)) for _ in range(rowCount)],\n",
    "                  'weight': [random.uniform(0, 2) for _ in range(rowCount)],\n",
    "                  'qty': [random.randint(0, 100) for _ in range(rowCount)],\n",
    "                  'risk': [random.randint(0, 10) for _ in range(rowCount)]}), NROFCORES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn(t):\n",
    "    res = t.groupby('bucket').agg({'bucket': 'count', 'qty': [sum, np.mean], 'risk': [sum, np.mean]}).compute()\n",
    "    res.columns = res.columns.map('_'.join)\n",
    "    return res.rename(columns={'bucket_count':'NR', 'qty_sum':'TOTAL_QTY','qty_mean':'AVG_QTY', \n",
    "                        'risk_sum':'TOTAL_RISK','risk_mean':'AVG_RISK'}).join(\n",
    "        t.groupby('bucket').apply(lambda g: np.average(g.qty, weights=g.weight), meta=('x', 'f8')).to_frame('W_AVG_QTY').compute()).join(\n",
    "        t.groupby('bucket').apply(lambda g: np.average(g.risk, weights=g.weight), meta=('x', 'f8')).to_frame('W_AVG_RISK').compute())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_agg(x):\n",
    "    data = {'NR': x.bucket.count(),\n",
    "            'TOTAL_QTY': x.qty.sum(),\n",
    "            'AVG_QTY': x.qty.mean(),\n",
    "            'TOTAL_RISK': x.risk.sum(),\n",
    "            'AVG_RISK': x.risk.mean(),\n",
    "            'W_AVG_QTY':  np.average(x.qty, weights=x.weight),\n",
    "            'W_AVG_RISK':  np.average(x.risk, weights=x.weight)\n",
    "           }\n",
    "    return pd.Series(data, index=['NR', 'TOTAL_QTY', 'AVG_QTY', 'TOTAL_RISK', \n",
    "                                  'AVG_RISK', 'W_AVG_QTY', 'W_AVG_RISK'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Row Number 10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = createTable(10 * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "906 ms ± 4.87 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit fn(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.38 s ± 8.33 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit t.groupby('bucket').apply(my_agg, \\\n",
    "    meta={'NR': 'i8', 'TOTAL_QTY': 'i8', 'AVG_QTY': 'f8', 'TOTAL_RISK': 'i8', 'AVG_RISK': 'f8', 'W_AVG_QTY': 'f8', 'W_AVG_RISK': 'f8'}) \\\n",
    "    .compute().astype({'NR': 'int64', 'TOTAL_QTY': 'int64', 'TOTAL_RISK': 'int64'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Row Number 100k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = createTable(100 * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12 s ± 6.13 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit fn(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5 s ± 8.84 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit t.groupby('bucket').apply(my_agg, \\\n",
    "    meta={'NR': 'i8', 'TOTAL_QTY': 'i8', 'AVG_QTY': 'f8', 'TOTAL_RISK': 'i8', 'AVG_RISK': 'f8', 'W_AVG_QTY': 'f8', 'W_AVG_RISK': 'f8'}) \\\n",
    "    .compute().astype({'NR': 'int64', 'TOTAL_QTY': 'int64', 'TOTAL_RISK': 'int64'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Row Number 1M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = createTable(1000 * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.79 s ± 31.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit fn(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.62 s ± 13.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit t.groupby('bucket').apply(my_agg, \\\n",
    "    meta={'NR': 'i8', 'TOTAL_QTY': 'i8', 'AVG_QTY': 'f8', 'TOTAL_RISK': 'i8', 'AVG_RISK': 'f8', 'W_AVG_QTY': 'f8', 'W_AVG_RISK': 'f8'}) \\\n",
    "    .compute().astype({'NR': 'int64', 'TOTAL_QTY': 'int64', 'TOTAL_RISK': 'int64'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Row Number 10M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = createTable(10 * 1000 * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 s ± 959 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit fn(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.4 s ± 247 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit t.groupby('bucket').apply(my_agg, \\\n",
    "    meta={'NR': 'i8', 'TOTAL_QTY': 'i8', 'AVG_QTY': 'f8', 'TOTAL_RISK': 'i8', 'AVG_RISK': 'f8', 'W_AVG_QTY': 'f8', 'W_AVG_RISK': 'f8'}) \\\n",
    "    .compute().astype({'NR': 'int64', 'TOTAL_QTY': 'int64', 'TOTAL_RISK': 'int64'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
